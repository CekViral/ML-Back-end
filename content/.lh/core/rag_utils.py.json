{
    "sourceFile": "core/rag_utils.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 13,
            "patches": [
                {
                    "date": 1748705020203,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1748705063987,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,7 @@\n from core.config import model\r\n+from core.embedding import embed_query\r\n+from core.database import connect_db\r\n \r\n def search_similar_docs(conn, query_vector, top_k):\r\n     cursor = conn.cursor()\r\n     vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n"
                },
                {
                    "date": 1748705517441,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,5 @@\n from core.config import model\r\n-from core.embedding import embed_query\r\n-from core.database import connect_db\r\n \r\n def search_similar_docs(conn, query_vector, top_k):\r\n     cursor = conn.cursor()\r\n     vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n@@ -31,17 +29,5 @@\n         return response.text\r\n     except Exception as e:\r\n         import traceback\r\n         traceback.print_exc()\r\n-        return \"Terjadi error saat memproses jawaban dari Gemini API.\"\r\n-\r\n-def rag_pipeline(question: str):\r\n-    conn = connect_db()\r\n-    try:\r\n-        query_vec = embed_query(question)\r\n-        docs = search_similar_docs(conn, query_vec)\r\n-        if not docs:\r\n-            return \"Maaf, tidak ditemukan informasi relevan.\"\r\n-        context = \"\\n\\n\".join([f\"- {title}\\n{desc}\" for title, desc in docs])\r\n-        return generate_answer(context, question)\r\n-    finally:\r\n-        conn.close()\n\\ No newline at end of file\n+        return \"Terjadi error saat memproses jawaban dari Gemini API.\"\n\\ No newline at end of file\n"
                },
                {
                    "date": 1748706554088,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,6 @@\n from core.config import model\r\n+from core.embedding import embed_query\r\n \r\n def search_similar_docs(conn, query_vector, top_k):\r\n     cursor = conn.cursor()\r\n     vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n@@ -29,5 +30,16 @@\n         return response.text\r\n     except Exception as e:\r\n         import traceback\r\n         traceback.print_exc()\r\n-        return \"Terjadi error saat memproses jawaban dari Gemini API.\"\n\\ No newline at end of file\n+        return \"Terjadi error saat memproses jawaban dari Gemini API.\"\r\n+\r\n+def rag_pipeline(question: str, conn):\r\n+    query_vec = embed_query(question)\r\n+    docs = search_similar_docs(conn, query_vec)\r\n+    \r\n+    if not docs:\r\n+        return \"Maaf, tidak ditemukan informasi relevan.\"\r\n+\r\n+    context = \"\\n\\n\".join([f\"- {title}\\n{desc}\" for title, desc in docs])\r\n+    answer = generate_answer(context, question)\r\n+    return answer\n\\ No newline at end of file\n"
                },
                {
                    "date": 1748707265650,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,14 +32,12 @@\n         import traceback\r\n         traceback.print_exc()\r\n         return \"Terjadi error saat memproses jawaban dari Gemini API.\"\r\n \r\n-def rag_pipeline(question: str, conn):\r\n+def rag_pipeline(question: str, conn, top_k: int = 5):  # ← tambahkan top_k di parameter\r\n     query_vec = embed_query(question)\r\n-    docs = search_similar_docs(conn, query_vec)\r\n-    \r\n+    docs = search_similar_docs(conn, query_vec, top_k=top_k)  # ← kirim ke search\r\n     if not docs:\r\n         return \"Maaf, tidak ditemukan informasi relevan.\"\r\n-\r\n     context = \"\\n\\n\".join([f\"- {title}\\n{desc}\" for title, desc in docs])\r\n\\ No newline at end of file\n     answer = generate_answer(context, question)\r\n-    return answer\n+    return answer\r\n"
                },
                {
                    "date": 1748707412439,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,13 +31,4 @@\n     except Exception as e:\r\n         import traceback\r\n         traceback.print_exc()\r\n         return \"Terjadi error saat memproses jawaban dari Gemini API.\"\r\n-\r\n-def rag_pipeline(question: str, conn, top_k: int = 5):  # ← tambahkan top_k di parameter\r\n-    query_vec = embed_query(question)\r\n-    docs = search_similar_docs(conn, query_vec, top_k=top_k)  # ← kirim ke search\r\n-    if not docs:\r\n-        return \"Maaf, tidak ditemukan informasi relevan.\"\r\n-    context = \"\\n\\n\".join([f\"- {title}\\n{desc}\" for title, desc in docs])\r\n-    answer = generate_answer(context, question)\r\n-    return answer\n\\ No newline at end of file\n"
                },
                {
                    "date": 1748707883930,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,9 +5,9 @@\n     cursor = conn.cursor()\r\n     vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n     cursor.execute(\r\n         \"\"\"\r\n-        SELECT title, cleaned_description\r\n+        SELECT title, link, imageurl\r\n         FROM news_data\r\n         ORDER BY vector <#> %s::vector\r\n         LIMIT %s;\r\n         \"\"\",\r\n"
                },
                {
                    "date": 1748708507676,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,23 +1,29 @@\n from core.config import model\r\n from core.embedding import embed_query\r\n \r\n-def search_similar_docs(conn, query_vector, top_k):\r\n+\r\n+def search_docs_for_rag(conn, query_vector, top_k=5):\r\n     cursor = conn.cursor()\r\n-    vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n-    cursor.execute(\r\n-        \"\"\"\r\n-        SELECT title, link, imageurl\r\n-        FROM news_data\r\n-        ORDER BY vector <#> %s::vector\r\n-        LIMIT %s;\r\n-        \"\"\",\r\n-        (vector_str, top_k)\r\n-    )\r\n-    results = cursor.fetchall()\r\n-    cursor.close()\r\n-    return results\r\n+    # Misalnya kamu menyimpan embedding sebagai vektor\r\n+    cursor.execute(\"\"\"\r\n+        SELECT status, title, cleaned_description FROM news_data\r\n+        ORDER BY embedding <#> %s\r\n+        LIMIT %s\r\n+    \"\"\", (query_vector.tolist(), top_k))\r\n+    return cursor.fetchall()\r\n \r\n+\r\n+def search_docs_for_rekomendasi(conn, query_vector, top_k=8):\r\n+    cursor = conn.cursor()\r\n+    cursor.execute(\"\"\"\r\n+        SELECT title, link, imageurl FROM rekomendasi_data\r\n+        ORDER BY embedding <#> %s\r\n+        LIMIT %s\r\n+    \"\"\", (query_vector.tolist(), top_k))\r\n+    return cursor.fetchall()\r\n+\r\n+\r\n def generate_answer(context: str, question: str) -> str:\r\n     prompt = f\"\"\"Berikut adalah informasi relevan:\r\n {context}\r\n \r\n"
                },
                {
                    "date": 1748708675839,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,9 +5,9 @@\n def search_docs_for_rag(conn, query_vector, top_k=5):\r\n     cursor = conn.cursor()\r\n     # Misalnya kamu menyimpan embedding sebagai vektor\r\n     cursor.execute(\"\"\"\r\n-        SELECT status, title, cleaned_description FROM news_data\r\n+        SELECT status, title, description FROM news_data\r\n         ORDER BY embedding <#> %s\r\n         LIMIT %s\r\n     \"\"\", (query_vector.tolist(), top_k))\r\n     return cursor.fetchall()\r\n"
                },
                {
                    "date": 1748708891404,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,9 +8,9 @@\n     cursor.execute(\"\"\"\r\n         SELECT status, title, description FROM news_data\r\n         ORDER BY embedding <#> %s\r\n         LIMIT %s\r\n-    \"\"\", (query_vector.tolist(), top_k))\r\n+    \"\"\", (query_vector, top_k))\r\n     return cursor.fetchall()\r\n \r\n \r\n def search_docs_for_rekomendasi(conn, query_vector, top_k=8):\r\n@@ -18,9 +18,9 @@\n     cursor.execute(\"\"\"\r\n         SELECT title, link, imageurl FROM rekomendasi_data\r\n         ORDER BY embedding <#> %s\r\n         LIMIT %s\r\n-    \"\"\", (query_vector.tolist(), top_k))\r\n+    \"\"\", (query_vector, top_k))\r\n     return cursor.fetchall()\r\n \r\n \r\n def generate_answer(context: str, question: str) -> str:\r\n"
                },
                {
                    "date": 1748709081219,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,9 +6,9 @@\n     cursor = conn.cursor()\r\n     # Misalnya kamu menyimpan embedding sebagai vektor\r\n     cursor.execute(\"\"\"\r\n         SELECT status, title, description FROM news_data\r\n-        ORDER BY embedding <#> %s\r\n+        ORDER BY vector <#> %s\r\n         LIMIT %s\r\n     \"\"\", (query_vector, top_k))\r\n     return cursor.fetchall()\r\n \r\n@@ -16,9 +16,9 @@\n def search_docs_for_rekomendasi(conn, query_vector, top_k=8):\r\n     cursor = conn.cursor()\r\n     cursor.execute(\"\"\"\r\n         SELECT title, link, imageurl FROM rekomendasi_data\r\n-        ORDER BY embedding <#> %s\r\n+        ORDER BY vector <#> %s\r\n         LIMIT %s\r\n     \"\"\", (query_vector, top_k))\r\n     return cursor.fetchall()\r\n \r\n"
                },
                {
                    "date": 1748709417463,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,27 +3,30 @@\n \r\n \r\n def search_docs_for_rag(conn, query_vector, top_k=5):\r\n     cursor = conn.cursor()\r\n-    # Misalnya kamu menyimpan embedding sebagai vektor\r\n+    vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n     cursor.execute(\"\"\"\r\n         SELECT status, title, description FROM news_data\r\n-        ORDER BY vector <#> %s\r\n-        LIMIT %s\r\n-    \"\"\", (query_vector, top_k))\r\n-    return cursor.fetchall()\r\n+        ORDER BY vector <#> %s::vector\r\n+        LIMIT %s;\r\n+    \"\"\", (vector_str, top_k))\r\n+    results = cursor.fetchall()\r\n+    cursor.close()\r\n+    return results\r\n \r\n-\r\n def search_docs_for_rekomendasi(conn, query_vector, top_k=8):\r\n     cursor = conn.cursor()\r\n+    vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n     cursor.execute(\"\"\"\r\n         SELECT title, link, imageurl FROM rekomendasi_data\r\n-        ORDER BY vector <#> %s\r\n-        LIMIT %s\r\n-    \"\"\", (query_vector, top_k))\r\n-    return cursor.fetchall()\r\n+        ORDER BY vector <#> %s::vector\r\n+        LIMIT %s;\r\n+    \"\"\", (vector_str, top_k))\r\n+    results = cursor.fetchall()\r\n+    cursor.close()\r\n+    return results\r\n \r\n-\r\n def generate_answer(context: str, question: str) -> str:\r\n     prompt = f\"\"\"Berikut adalah informasi relevan:\r\n {context}\r\n \r\n"
                },
                {
                    "date": 1748709426268,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,45 @@\n+from core.config import model\r\n+from core.embedding import embed_query\r\n+\r\n+\r\n+def search_docs_for_rag(conn, query_vector, top_k=5):\r\n+    cursor = conn.cursor()\r\n+    vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n+    cursor.execute(\"\"\"\r\n+        SELECT status, title, description FROM news_data\r\n+        ORDER BY vector <#> %s::vector\r\n+        LIMIT %s;\r\n+    \"\"\", (vector_str, top_k))\r\n+    results = cursor.fetchall()\r\n+    cursor.close()\r\n+    return results\r\n+\r\n+\r\n+def search_docs_for_rekomendasi(conn, query_vector, top_k=8):\r\n+    cursor = conn.cursor()\r\n+    vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n+    cursor.execute(\"\"\"\r\n+        SELECT title, link, imageurl FROM rekomendasi_data\r\n+        ORDER BY vector <#> %s::vector\r\n+        LIMIT %s;\r\n+    \"\"\", (vector_str, top_k))\r\n+    results = cursor.fetchall()\r\n+    cursor.close()\r\n+    return results\r\n+\r\n+\r\n+def generate_answer(context: str, question: str) -> str:\r\n+    prompt = f\"\"\"Berikut adalah informasi relevan:\r\n+{context}\r\n+\r\n+Jadi Anda adalah seorang ahli yang diminta untuk menjelaskan apakah input dari\r\n+user di bawah ini adalah konten asli atau hoax berdasarkan informasi yang tertera di atas:\r\n+{question}\r\n+\"\"\"\r\n+    try:\r\n+        response = model.generate_content(prompt)\r\n+        return response.text\r\n+    except Exception as e:\r\n+        import traceback\r\n+        traceback.print_exc()\r\n+        return \"Terjadi error saat memproses jawaban dari Gemini API.\"\r\n"
                },
                {
                    "date": 1748709517072,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n def search_docs_for_rekomendasi(conn, query_vector, top_k=8):\r\n     cursor = conn.cursor()\r\n     vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n     cursor.execute(\"\"\"\r\n-        SELECT title, link, imageurl FROM rekomendasi_data\r\n+        SELECT title, link, imageurl FROM news_data\r\n         ORDER BY vector <#> %s::vector\r\n         LIMIT %s;\r\n     \"\"\", (vector_str, top_k))\r\n     results = cursor.fetchall()\r\n@@ -42,47 +42,4 @@\n     except Exception as e:\r\n         import traceback\r\n         traceback.print_exc()\r\n         return \"Terjadi error saat memproses jawaban dari Gemini API.\"\r\n-from core.config import model\r\n-from core.embedding import embed_query\r\n-\r\n-\r\n-def search_docs_for_rag(conn, query_vector, top_k=5):\r\n-    cursor = conn.cursor()\r\n-    vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n-    cursor.execute(\"\"\"\r\n-        SELECT status, title, description FROM news_data\r\n-        ORDER BY vector <#> %s::vector\r\n-        LIMIT %s;\r\n-    \"\"\", (vector_str, top_k))\r\n-    results = cursor.fetchall()\r\n-    cursor.close()\r\n-    return results\r\n-\r\n-def search_docs_for_rekomendasi(conn, query_vector, top_k=8):\r\n-    cursor = conn.cursor()\r\n-    vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n-    cursor.execute(\"\"\"\r\n-        SELECT title, link, imageurl FROM rekomendasi_data\r\n-        ORDER BY vector <#> %s::vector\r\n-        LIMIT %s;\r\n-    \"\"\", (vector_str, top_k))\r\n-    results = cursor.fetchall()\r\n-    cursor.close()\r\n-    return results\r\n-\r\n-def generate_answer(context: str, question: str) -> str:\r\n-    prompt = f\"\"\"Berikut adalah informasi relevan:\r\n-{context}\r\n-\r\n-Jadi Anda adalah seorang ahli yang diminta untuk menjelaskan apakah input dari\r\n-user di bawah ini adalah konten asli atau hoax berdasarkan informasi yang tertera di atas:\r\n-{question}\r\n-\"\"\"\r\n-    try:\r\n-        response = model.generate_content(prompt)\r\n-        return response.text\r\n-    except Exception as e:\r\n-        import traceback\r\n-        traceback.print_exc()\r\n-        return \"Terjadi error saat memproses jawaban dari Gemini API.\"\r\n"
                }
            ],
            "date": 1748705020203,
            "name": "Commit-0",
            "content": "from core.config import model\r\n\r\ndef search_similar_docs(conn, query_vector, top_k):\r\n    cursor = conn.cursor()\r\n    vector_str = \"[\" + \",\".join(map(str, query_vector)) + \"]\"\r\n    cursor.execute(\r\n        \"\"\"\r\n        SELECT title, cleaned_description\r\n        FROM news_data\r\n        ORDER BY vector <#> %s::vector\r\n        LIMIT %s;\r\n        \"\"\",\r\n        (vector_str, top_k)\r\n    )\r\n    results = cursor.fetchall()\r\n    cursor.close()\r\n    return results\r\n\r\ndef generate_answer(context: str, question: str) -> str:\r\n    prompt = f\"\"\"Berikut adalah informasi relevan:\r\n{context}\r\n\r\nJadi Anda adalah seorang ahli yang diminta untuk menjelaskan apakah input dari\r\nuser di bawah ini adalah konten asli atau hoax berdasarkan informasi yang tertera di atas:\r\n{question}\r\n\"\"\"\r\n    try:\r\n        response = model.generate_content(prompt)\r\n        return response.text\r\n    except Exception as e:\r\n        import traceback\r\n        traceback.print_exc()\r\n        return \"Terjadi error saat memproses jawaban dari Gemini API.\"\r\n\r\ndef rag_pipeline(question: str):\r\n    conn = connect_db()\r\n    try:\r\n        query_vec = embed_query(question)\r\n        docs = search_similar_docs(conn, query_vec)\r\n        if not docs:\r\n            return \"Maaf, tidak ditemukan informasi relevan.\"\r\n        context = \"\\n\\n\".join([f\"- {title}\\n{desc}\" for title, desc in docs])\r\n        return generate_answer(context, question)\r\n    finally:\r\n        conn.close()"
        }
    ]
}